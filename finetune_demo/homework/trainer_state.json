{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2094240837696335,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 2.174236297607422,
      "learning_rate": 4.991666666666667e-05,
      "loss": 4.8332,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.139665365219116,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 4.6074,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.986734390258789,
      "learning_rate": 4.975e-05,
      "loss": 4.4961,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.4064061641693115,
      "learning_rate": 4.966666666666667e-05,
      "loss": 4.1328,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.745936632156372,
      "learning_rate": 4.958333333333334e-05,
      "loss": 4.1232,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.9336040019989014,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.8699,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.8663105964660645,
      "learning_rate": 4.9416666666666664e-05,
      "loss": 3.843,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.945251226425171,
      "learning_rate": 4.933333333333334e-05,
      "loss": 3.7475,
      "step": 80
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.2352662086486816,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 3.634,
      "step": 90
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.3570713996887207,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 3.7199,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.589273452758789,
      "learning_rate": 4.908333333333334e-05,
      "loss": 3.6695,
      "step": 110
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.898731231689453,
      "learning_rate": 4.9e-05,
      "loss": 3.8492,
      "step": 120
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.4922749996185303,
      "learning_rate": 4.891666666666667e-05,
      "loss": 3.6137,
      "step": 130
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.462913990020752,
      "learning_rate": 4.883333333333334e-05,
      "loss": 3.7299,
      "step": 140
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.6523265838623047,
      "learning_rate": 4.875e-05,
      "loss": 3.6838,
      "step": 150
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.91763973236084,
      "learning_rate": 4.866666666666667e-05,
      "loss": 3.7432,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.122247219085693,
      "learning_rate": 4.858333333333333e-05,
      "loss": 3.5736,
      "step": 170
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.330429553985596,
      "learning_rate": 4.85e-05,
      "loss": 3.574,
      "step": 180
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.734687805175781,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 3.55,
      "step": 190
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.491717338562012,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 3.5752,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.985267639160156,
      "learning_rate": 4.825e-05,
      "loss": 3.5498,
      "step": 210
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.051936149597168,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 3.6432,
      "step": 220
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.77301025390625,
      "learning_rate": 4.8083333333333334e-05,
      "loss": 3.6096,
      "step": 230
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.510164260864258,
      "learning_rate": 4.8e-05,
      "loss": 3.5115,
      "step": 240
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.395442008972168,
      "learning_rate": 4.791666666666667e-05,
      "loss": 3.475,
      "step": 250
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.3722076416015625,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 3.6023,
      "step": 260
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.418113708496094,
      "learning_rate": 4.775e-05,
      "loss": 3.548,
      "step": 270
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.559344291687012,
      "learning_rate": 4.766666666666667e-05,
      "loss": 3.6117,
      "step": 280
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.829887390136719,
      "learning_rate": 4.7583333333333336e-05,
      "loss": 3.6277,
      "step": 290
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.81113338470459,
      "learning_rate": 4.75e-05,
      "loss": 3.5381,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.317930221557617,
      "learning_rate": 4.741666666666667e-05,
      "loss": 3.4682,
      "step": 310
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.782290935516357,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 3.607,
      "step": 320
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.206994533538818,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 3.418,
      "step": 330
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.421177864074707,
      "learning_rate": 4.716666666666667e-05,
      "loss": 3.492,
      "step": 340
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.489384174346924,
      "learning_rate": 4.708333333333334e-05,
      "loss": 3.5199,
      "step": 350
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.220513820648193,
      "learning_rate": 4.7e-05,
      "loss": 3.5744,
      "step": 360
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.870863437652588,
      "learning_rate": 4.691666666666667e-05,
      "loss": 3.359,
      "step": 370
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.173522472381592,
      "learning_rate": 4.683333333333334e-05,
      "loss": 3.5309,
      "step": 380
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.336514949798584,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 3.5234,
      "step": 390
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.6570611000061035,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.4711,
      "step": 400
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.523419380187988,
      "learning_rate": 4.658333333333333e-05,
      "loss": 3.6873,
      "step": 410
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.060326099395752,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.4965,
      "step": 420
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.657813549041748,
      "learning_rate": 4.641666666666667e-05,
      "loss": 3.6227,
      "step": 430
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.723987102508545,
      "learning_rate": 4.633333333333333e-05,
      "loss": 3.4186,
      "step": 440
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.153532981872559,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 3.4141,
      "step": 450
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.619359493255615,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 3.4256,
      "step": 460
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.834824085235596,
      "learning_rate": 4.608333333333333e-05,
      "loss": 3.5316,
      "step": 470
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.15020751953125,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.4469,
      "step": 480
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.761536598205566,
      "learning_rate": 4.591666666666667e-05,
      "loss": 3.4535,
      "step": 490
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.9504075050354,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 3.5607,
      "step": 500
    },
    {
      "epoch": 0.02,
      "eval_bleu-4": 0.0322556303758815,
      "eval_rouge-1": 31.822212,
      "eval_rouge-2": 6.986868,
      "eval_rouge-l": 24.038528,
      "eval_runtime": 45.9029,
      "eval_samples_per_second": 1.089,
      "eval_steps_per_second": 0.087,
      "step": 500
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.805620193481445,
      "learning_rate": 4.575e-05,
      "loss": 3.3223,
      "step": 510
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.690407752990723,
      "learning_rate": 4.566666666666667e-05,
      "loss": 3.5434,
      "step": 520
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.95470666885376,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 3.5811,
      "step": 530
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.403108596801758,
      "learning_rate": 4.55e-05,
      "loss": 3.4832,
      "step": 540
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.439948081970215,
      "learning_rate": 4.541666666666667e-05,
      "loss": 3.5266,
      "step": 550
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.837973117828369,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 3.6422,
      "step": 560
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.786936283111572,
      "learning_rate": 4.525e-05,
      "loss": 3.4891,
      "step": 570
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.632689476013184,
      "learning_rate": 4.516666666666667e-05,
      "loss": 3.3721,
      "step": 580
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.305208206176758,
      "learning_rate": 4.5083333333333336e-05,
      "loss": 3.4234,
      "step": 590
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.526435852050781,
      "learning_rate": 4.5e-05,
      "loss": 3.4893,
      "step": 600
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.173710346221924,
      "learning_rate": 4.491666666666667e-05,
      "loss": 3.4371,
      "step": 610
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.664087772369385,
      "learning_rate": 4.483333333333333e-05,
      "loss": 3.4545,
      "step": 620
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.98048734664917,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 3.4432,
      "step": 630
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.321861267089844,
      "learning_rate": 4.466666666666667e-05,
      "loss": 3.4559,
      "step": 640
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.949871063232422,
      "learning_rate": 4.458333333333334e-05,
      "loss": 3.5328,
      "step": 650
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.503711700439453,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.4814,
      "step": 660
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.0746169090271,
      "learning_rate": 4.4416666666666664e-05,
      "loss": 3.5377,
      "step": 670
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.049829483032227,
      "learning_rate": 4.433333333333334e-05,
      "loss": 3.2994,
      "step": 680
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.6886773109436035,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 3.3984,
      "step": 690
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.245993614196777,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 3.3523,
      "step": 700
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.1516032218933105,
      "learning_rate": 4.408333333333334e-05,
      "loss": 3.5016,
      "step": 710
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.762241840362549,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.5262,
      "step": 720
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.9815263748168945,
      "learning_rate": 4.3916666666666666e-05,
      "loss": 3.2439,
      "step": 730
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.877453327178955,
      "learning_rate": 4.383333333333334e-05,
      "loss": 3.5732,
      "step": 740
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.5381927490234375,
      "learning_rate": 4.375e-05,
      "loss": 3.3947,
      "step": 750
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.107861042022705,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 3.4771,
      "step": 760
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.403555393218994,
      "learning_rate": 4.358333333333334e-05,
      "loss": 3.6197,
      "step": 770
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.410215377807617,
      "learning_rate": 4.35e-05,
      "loss": 3.4715,
      "step": 780
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.475851535797119,
      "learning_rate": 4.341666666666667e-05,
      "loss": 3.3225,
      "step": 790
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.81561803817749,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 3.5479,
      "step": 800
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.734149932861328,
      "learning_rate": 4.325e-05,
      "loss": 3.2879,
      "step": 810
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.480576038360596,
      "learning_rate": 4.316666666666667e-05,
      "loss": 3.3615,
      "step": 820
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.169713973999023,
      "learning_rate": 4.3083333333333335e-05,
      "loss": 3.4586,
      "step": 830
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.322657585144043,
      "learning_rate": 4.3e-05,
      "loss": 3.4041,
      "step": 840
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.199166297912598,
      "learning_rate": 4.291666666666667e-05,
      "loss": 3.5045,
      "step": 850
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.293325901031494,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 3.534,
      "step": 860
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.241891860961914,
      "learning_rate": 4.275e-05,
      "loss": 3.2945,
      "step": 870
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.7857818603515625,
      "learning_rate": 4.266666666666667e-05,
      "loss": 3.49,
      "step": 880
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.448591232299805,
      "learning_rate": 4.2583333333333336e-05,
      "loss": 3.4492,
      "step": 890
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.03514289855957,
      "learning_rate": 4.25e-05,
      "loss": 3.2629,
      "step": 900
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.737720012664795,
      "learning_rate": 4.241666666666667e-05,
      "loss": 3.4631,
      "step": 910
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.937031269073486,
      "learning_rate": 4.233333333333334e-05,
      "loss": 3.4215,
      "step": 920
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.517177104949951,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 3.4562,
      "step": 930
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.370781898498535,
      "learning_rate": 4.216666666666667e-05,
      "loss": 3.5672,
      "step": 940
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.434891700744629,
      "learning_rate": 4.208333333333334e-05,
      "loss": 3.3631,
      "step": 950
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.023599624633789,
      "learning_rate": 4.2e-05,
      "loss": 3.4395,
      "step": 960
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.870826244354248,
      "learning_rate": 4.191666666666667e-05,
      "loss": 3.5273,
      "step": 970
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.9718828201293945,
      "learning_rate": 4.183333333333334e-05,
      "loss": 3.323,
      "step": 980
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.264352798461914,
      "learning_rate": 4.175e-05,
      "loss": 3.4588,
      "step": 990
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.792730331420898,
      "learning_rate": 4.166666666666667e-05,
      "loss": 3.3953,
      "step": 1000
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.03478622680907595,
      "eval_rouge-1": 32.282978,
      "eval_rouge-2": 6.886938000000002,
      "eval_rouge-l": 25.83951,
      "eval_runtime": 12.287,
      "eval_samples_per_second": 4.069,
      "eval_steps_per_second": 0.326,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.861582279205322,
      "learning_rate": 4.158333333333333e-05,
      "loss": 3.4475,
      "step": 1010
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.369497776031494,
      "learning_rate": 4.15e-05,
      "loss": 3.4535,
      "step": 1020
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.113160133361816,
      "learning_rate": 4.141666666666667e-05,
      "loss": 3.65,
      "step": 1030
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.4849066734313965,
      "learning_rate": 4.133333333333333e-05,
      "loss": 3.4041,
      "step": 1040
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.618846893310547,
      "learning_rate": 4.125e-05,
      "loss": 3.3883,
      "step": 1050
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.907746315002441,
      "learning_rate": 4.116666666666667e-05,
      "loss": 3.3561,
      "step": 1060
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.0375895500183105,
      "learning_rate": 4.1083333333333334e-05,
      "loss": 3.3889,
      "step": 1070
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.320917129516602,
      "learning_rate": 4.1e-05,
      "loss": 3.459,
      "step": 1080
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.088146686553955,
      "learning_rate": 4.091666666666667e-05,
      "loss": 3.5264,
      "step": 1090
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.442445278167725,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 3.4686,
      "step": 1100
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.787782192230225,
      "learning_rate": 4.075e-05,
      "loss": 3.3436,
      "step": 1110
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.92279577255249,
      "learning_rate": 4.066666666666667e-05,
      "loss": 3.5234,
      "step": 1120
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.230950832366943,
      "learning_rate": 4.0583333333333335e-05,
      "loss": 3.4355,
      "step": 1130
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.040611267089844,
      "learning_rate": 4.05e-05,
      "loss": 3.3607,
      "step": 1140
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.543755531311035,
      "learning_rate": 4.041666666666667e-05,
      "loss": 3.3205,
      "step": 1150
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.142161846160889,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 3.3617,
      "step": 1160
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.559029579162598,
      "learning_rate": 4.025e-05,
      "loss": 3.4498,
      "step": 1170
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.289588451385498,
      "learning_rate": 4.016666666666667e-05,
      "loss": 3.4697,
      "step": 1180
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.473840713500977,
      "learning_rate": 4.0083333333333336e-05,
      "loss": 3.3605,
      "step": 1190
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.306177139282227,
      "learning_rate": 4e-05,
      "loss": 3.4119,
      "step": 1200
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.569748401641846,
      "learning_rate": 3.991666666666667e-05,
      "loss": 3.2467,
      "step": 1210
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.227006912231445,
      "learning_rate": 3.983333333333333e-05,
      "loss": 3.3365,
      "step": 1220
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.286154270172119,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 3.3752,
      "step": 1230
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.814704895019531,
      "learning_rate": 3.966666666666667e-05,
      "loss": 3.3773,
      "step": 1240
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.60188102722168,
      "learning_rate": 3.958333333333333e-05,
      "loss": 3.4453,
      "step": 1250
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.461679935455322,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.2844,
      "step": 1260
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.028886318206787,
      "learning_rate": 3.941666666666667e-05,
      "loss": 3.4566,
      "step": 1270
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.968334197998047,
      "learning_rate": 3.933333333333333e-05,
      "loss": 3.332,
      "step": 1280
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.667600154876709,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 3.3818,
      "step": 1290
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.404262065887451,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 3.483,
      "step": 1300
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.853451251983643,
      "learning_rate": 3.908333333333333e-05,
      "loss": 3.4631,
      "step": 1310
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.564682483673096,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.4553,
      "step": 1320
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.403417587280273,
      "learning_rate": 3.8916666666666666e-05,
      "loss": 3.4047,
      "step": 1330
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.4346022605896,
      "learning_rate": 3.883333333333333e-05,
      "loss": 3.3062,
      "step": 1340
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.589252471923828,
      "learning_rate": 3.875e-05,
      "loss": 3.351,
      "step": 1350
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.998233318328857,
      "learning_rate": 3.866666666666667e-05,
      "loss": 3.2969,
      "step": 1360
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.120832443237305,
      "learning_rate": 3.8583333333333334e-05,
      "loss": 3.5158,
      "step": 1370
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.085773468017578,
      "learning_rate": 3.85e-05,
      "loss": 3.3822,
      "step": 1380
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.006824016571045,
      "learning_rate": 3.841666666666667e-05,
      "loss": 3.3594,
      "step": 1390
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.500309467315674,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 3.4189,
      "step": 1400
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.347240447998047,
      "learning_rate": 3.825e-05,
      "loss": 3.3453,
      "step": 1410
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.554381370544434,
      "learning_rate": 3.816666666666667e-05,
      "loss": 3.2645,
      "step": 1420
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.600240707397461,
      "learning_rate": 3.8083333333333335e-05,
      "loss": 3.3807,
      "step": 1430
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.042953968048096,
      "learning_rate": 3.8e-05,
      "loss": 3.3574,
      "step": 1440
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.645942211151123,
      "learning_rate": 3.791666666666667e-05,
      "loss": 3.2637,
      "step": 1450
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.154151916503906,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 3.3947,
      "step": 1460
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.929546356201172,
      "learning_rate": 3.775e-05,
      "loss": 3.4381,
      "step": 1470
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.693999290466309,
      "learning_rate": 3.766666666666667e-05,
      "loss": 3.2975,
      "step": 1480
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.223423957824707,
      "learning_rate": 3.7583333333333337e-05,
      "loss": 3.4395,
      "step": 1490
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.705279350280762,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.4561,
      "step": 1500
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.0335206030511688,
      "eval_rouge-1": 32.612254,
      "eval_rouge-2": 6.7768939999999995,
      "eval_rouge-l": 25.251394,
      "eval_runtime": 30.214,
      "eval_samples_per_second": 1.655,
      "eval_steps_per_second": 0.132,
      "step": 1500
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.78459358215332,
      "learning_rate": 3.7416666666666664e-05,
      "loss": 3.3432,
      "step": 1510
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.035786628723145,
      "learning_rate": 3.733333333333334e-05,
      "loss": 3.3893,
      "step": 1520
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.202373504638672,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 3.4385,
      "step": 1530
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.765063762664795,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 3.3986,
      "step": 1540
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.043278694152832,
      "learning_rate": 3.708333333333334e-05,
      "loss": 3.4949,
      "step": 1550
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.227995872497559,
      "learning_rate": 3.7e-05,
      "loss": 3.4051,
      "step": 1560
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.644457817077637,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 3.4705,
      "step": 1570
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.6108078956604,
      "learning_rate": 3.683333333333334e-05,
      "loss": 3.4285,
      "step": 1580
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.178936004638672,
      "learning_rate": 3.675e-05,
      "loss": 3.5102,
      "step": 1590
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.0886406898498535,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 3.3941,
      "step": 1600
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.823164939880371,
      "learning_rate": 3.658333333333334e-05,
      "loss": 3.3678,
      "step": 1610
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.331968307495117,
      "learning_rate": 3.65e-05,
      "loss": 3.3668,
      "step": 1620
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.9553961753845215,
      "learning_rate": 3.641666666666667e-05,
      "loss": 3.4721,
      "step": 1630
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.822789192199707,
      "learning_rate": 3.633333333333333e-05,
      "loss": 3.3195,
      "step": 1640
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.440892696380615,
      "learning_rate": 3.625e-05,
      "loss": 3.3746,
      "step": 1650
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.742302417755127,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 3.3033,
      "step": 1660
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.134466171264648,
      "learning_rate": 3.6083333333333334e-05,
      "loss": 3.4711,
      "step": 1670
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.9082350730896,
      "learning_rate": 3.6e-05,
      "loss": 3.3691,
      "step": 1680
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.280430793762207,
      "learning_rate": 3.591666666666667e-05,
      "loss": 3.375,
      "step": 1690
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.77573299407959,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 3.5154,
      "step": 1700
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.260509014129639,
      "learning_rate": 3.575e-05,
      "loss": 3.457,
      "step": 1710
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.382129192352295,
      "learning_rate": 3.566666666666667e-05,
      "loss": 3.4982,
      "step": 1720
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.298370361328125,
      "learning_rate": 3.5583333333333335e-05,
      "loss": 3.4018,
      "step": 1730
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.155993938446045,
      "learning_rate": 3.55e-05,
      "loss": 3.4008,
      "step": 1740
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.439835071563721,
      "learning_rate": 3.541666666666667e-05,
      "loss": 3.4637,
      "step": 1750
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.495641231536865,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 3.4371,
      "step": 1760
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.270808219909668,
      "learning_rate": 3.525e-05,
      "loss": 3.3598,
      "step": 1770
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.861649036407471,
      "learning_rate": 3.516666666666667e-05,
      "loss": 3.3498,
      "step": 1780
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.938660621643066,
      "learning_rate": 3.508333333333334e-05,
      "loss": 3.3973,
      "step": 1790
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.658267498016357,
      "learning_rate": 3.5e-05,
      "loss": 3.3338,
      "step": 1800
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.782785415649414,
      "learning_rate": 3.491666666666667e-05,
      "loss": 3.3762,
      "step": 1810
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.449469089508057,
      "learning_rate": 3.483333333333334e-05,
      "loss": 3.335,
      "step": 1820
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.862414360046387,
      "learning_rate": 3.475e-05,
      "loss": 3.5748,
      "step": 1830
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.486858367919922,
      "learning_rate": 3.466666666666667e-05,
      "loss": 3.3455,
      "step": 1840
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.511604309082031,
      "learning_rate": 3.458333333333333e-05,
      "loss": 3.4928,
      "step": 1850
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.415843486785889,
      "learning_rate": 3.45e-05,
      "loss": 3.376,
      "step": 1860
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.964321136474609,
      "learning_rate": 3.441666666666667e-05,
      "loss": 3.3121,
      "step": 1870
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.186209201812744,
      "learning_rate": 3.433333333333333e-05,
      "loss": 3.3068,
      "step": 1880
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.097479343414307,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 3.3982,
      "step": 1890
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.6739912033081055,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 3.3711,
      "step": 1900
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.9196085929870605,
      "learning_rate": 3.408333333333333e-05,
      "loss": 3.3883,
      "step": 1910
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.079761028289795,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.4779,
      "step": 1920
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.393160820007324,
      "learning_rate": 3.391666666666667e-05,
      "loss": 3.2779,
      "step": 1930
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.392641544342041,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 3.4998,
      "step": 1940
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.744668960571289,
      "learning_rate": 3.375000000000001e-05,
      "loss": 3.3633,
      "step": 1950
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.512418746948242,
      "learning_rate": 3.366666666666667e-05,
      "loss": 3.2838,
      "step": 1960
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.433516979217529,
      "learning_rate": 3.3583333333333334e-05,
      "loss": 3.3695,
      "step": 1970
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.569231986999512,
      "learning_rate": 3.35e-05,
      "loss": 3.2346,
      "step": 1980
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.996344566345215,
      "learning_rate": 3.341666666666667e-05,
      "loss": 3.4088,
      "step": 1990
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.278440475463867,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 3.4656,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.03382730800982028,
      "eval_rouge-1": 31.56169,
      "eval_rouge-2": 6.799842,
      "eval_rouge-l": 23.99147,
      "eval_runtime": 47.9608,
      "eval_samples_per_second": 1.043,
      "eval_steps_per_second": 0.083,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.561328887939453,
      "learning_rate": 3.325e-05,
      "loss": 3.3818,
      "step": 2010
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.33019495010376,
      "learning_rate": 3.316666666666667e-05,
      "loss": 3.4889,
      "step": 2020
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.429351806640625,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 3.5559,
      "step": 2030
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.094208717346191,
      "learning_rate": 3.3e-05,
      "loss": 3.4924,
      "step": 2040
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.098153114318848,
      "learning_rate": 3.291666666666667e-05,
      "loss": 3.3666,
      "step": 2050
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.381101608276367,
      "learning_rate": 3.283333333333333e-05,
      "loss": 3.3277,
      "step": 2060
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.791431903839111,
      "learning_rate": 3.275e-05,
      "loss": 3.4443,
      "step": 2070
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.095276832580566,
      "learning_rate": 3.266666666666667e-05,
      "loss": 3.4119,
      "step": 2080
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.290351867675781,
      "learning_rate": 3.258333333333333e-05,
      "loss": 3.4307,
      "step": 2090
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.652771472930908,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.3604,
      "step": 2100
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.469227313995361,
      "learning_rate": 3.2416666666666664e-05,
      "loss": 3.284,
      "step": 2110
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.634838104248047,
      "learning_rate": 3.233333333333333e-05,
      "loss": 3.5811,
      "step": 2120
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.109986305236816,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 3.2541,
      "step": 2130
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.03276252746582,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 3.3547,
      "step": 2140
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.2647624015808105,
      "learning_rate": 3.208333333333334e-05,
      "loss": 3.3975,
      "step": 2150
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.101432800292969,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.5207,
      "step": 2160
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.181620121002197,
      "learning_rate": 3.1916666666666665e-05,
      "loss": 3.3969,
      "step": 2170
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.295844554901123,
      "learning_rate": 3.183333333333334e-05,
      "loss": 3.4195,
      "step": 2180
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.291009902954102,
      "learning_rate": 3.175e-05,
      "loss": 3.3531,
      "step": 2190
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.042482852935791,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 3.4297,
      "step": 2200
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.592225551605225,
      "learning_rate": 3.158333333333334e-05,
      "loss": 3.4533,
      "step": 2210
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.496403217315674,
      "learning_rate": 3.15e-05,
      "loss": 3.4154,
      "step": 2220
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.982000350952148,
      "learning_rate": 3.141666666666667e-05,
      "loss": 3.4189,
      "step": 2230
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.77650785446167,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 3.366,
      "step": 2240
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.25370979309082,
      "learning_rate": 3.125e-05,
      "loss": 3.2422,
      "step": 2250
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.7139058113098145,
      "learning_rate": 3.116666666666667e-05,
      "loss": 3.3518,
      "step": 2260
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.371329307556152,
      "learning_rate": 3.1083333333333334e-05,
      "loss": 3.4281,
      "step": 2270
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.399270534515381,
      "learning_rate": 3.1e-05,
      "loss": 3.468,
      "step": 2280
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.462782859802246,
      "learning_rate": 3.091666666666667e-05,
      "loss": 3.2891,
      "step": 2290
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.641587734222412,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 3.3504,
      "step": 2300
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.37412166595459,
      "learning_rate": 3.075e-05,
      "loss": 3.3143,
      "step": 2310
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.354846954345703,
      "learning_rate": 3.066666666666667e-05,
      "loss": 3.3287,
      "step": 2320
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.659618377685547,
      "learning_rate": 3.0583333333333336e-05,
      "loss": 3.3613,
      "step": 2330
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.330527305603027,
      "learning_rate": 3.05e-05,
      "loss": 3.3604,
      "step": 2340
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.326021194458008,
      "learning_rate": 3.0416666666666666e-05,
      "loss": 3.2594,
      "step": 2350
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.815989971160889,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 3.3857,
      "step": 2360
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.590084075927734,
      "learning_rate": 3.025e-05,
      "loss": 3.3504,
      "step": 2370
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.244688034057617,
      "learning_rate": 3.016666666666667e-05,
      "loss": 3.4867,
      "step": 2380
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.386357307434082,
      "learning_rate": 3.0083333333333337e-05,
      "loss": 3.224,
      "step": 2390
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.989319324493408,
      "learning_rate": 3e-05,
      "loss": 3.4549,
      "step": 2400
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.665729999542236,
      "learning_rate": 2.991666666666667e-05,
      "loss": 3.4521,
      "step": 2410
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.4807868003845215,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 3.2795,
      "step": 2420
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.139408111572266,
      "learning_rate": 2.975e-05,
      "loss": 3.3643,
      "step": 2430
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.709718227386475,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 3.3824,
      "step": 2440
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.238494396209717,
      "learning_rate": 2.9583333333333335e-05,
      "loss": 3.2697,
      "step": 2450
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.3538312911987305,
      "learning_rate": 2.95e-05,
      "loss": 3.3031,
      "step": 2460
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.204126358032227,
      "learning_rate": 2.941666666666667e-05,
      "loss": 3.2568,
      "step": 2470
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.317477226257324,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 3.4385,
      "step": 2480
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.436949253082275,
      "learning_rate": 2.925e-05,
      "loss": 3.4717,
      "step": 2490
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.315577507019043,
      "learning_rate": 2.916666666666667e-05,
      "loss": 3.3918,
      "step": 2500
    },
    {
      "epoch": 0.09,
      "eval_bleu-4": 0.03393087927577523,
      "eval_rouge-1": 32.127776000000004,
      "eval_rouge-2": 6.9853179999999995,
      "eval_rouge-l": 25.267287999999997,
      "eval_runtime": 15.1302,
      "eval_samples_per_second": 3.305,
      "eval_steps_per_second": 0.264,
      "step": 2500
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.957339763641357,
      "learning_rate": 2.9083333333333333e-05,
      "loss": 3.2912,
      "step": 2510
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.05548095703125,
      "learning_rate": 2.9e-05,
      "loss": 3.3363,
      "step": 2520
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.73513126373291,
      "learning_rate": 2.891666666666667e-05,
      "loss": 3.2437,
      "step": 2530
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.00208568572998,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 3.3908,
      "step": 2540
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.037515163421631,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 3.3863,
      "step": 2550
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.002239227294922,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 3.3916,
      "step": 2560
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.567891597747803,
      "learning_rate": 2.8583333333333335e-05,
      "loss": 3.4678,
      "step": 2570
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.312773704528809,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.4803,
      "step": 2580
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.905700206756592,
      "learning_rate": 2.841666666666667e-05,
      "loss": 3.3668,
      "step": 2590
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.227808952331543,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 3.4703,
      "step": 2600
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.778405666351318,
      "learning_rate": 2.825e-05,
      "loss": 3.3404,
      "step": 2610
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.474563121795654,
      "learning_rate": 2.816666666666667e-05,
      "loss": 3.4135,
      "step": 2620
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.5357666015625,
      "learning_rate": 2.8083333333333333e-05,
      "loss": 3.5164,
      "step": 2630
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.316903114318848,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.4467,
      "step": 2640
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.591179847717285,
      "learning_rate": 2.791666666666667e-05,
      "loss": 3.3947,
      "step": 2650
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.741941928863525,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 3.3434,
      "step": 2660
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.808055877685547,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 3.4102,
      "step": 2670
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.271851539611816,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 3.2645,
      "step": 2680
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.128739356994629,
      "learning_rate": 2.7583333333333334e-05,
      "loss": 3.4639,
      "step": 2690
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.738264083862305,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.4387,
      "step": 2700
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.926468849182129,
      "learning_rate": 2.7416666666666668e-05,
      "loss": 3.4199,
      "step": 2710
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.280683517456055,
      "learning_rate": 2.733333333333333e-05,
      "loss": 3.2451,
      "step": 2720
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.841843605041504,
      "learning_rate": 2.725e-05,
      "loss": 3.3791,
      "step": 2730
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.141597747802734,
      "learning_rate": 2.716666666666667e-05,
      "loss": 3.3787,
      "step": 2740
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.677543640136719,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 3.4484,
      "step": 2750
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.927738666534424,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.3967,
      "step": 2760
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.785528182983398,
      "learning_rate": 2.691666666666667e-05,
      "loss": 3.3461,
      "step": 2770
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.05752182006836,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 3.2502,
      "step": 2780
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.7140212059021,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 3.2742,
      "step": 2790
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.480787754058838,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 3.2318,
      "step": 2800
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.07050609588623,
      "learning_rate": 2.6583333333333333e-05,
      "loss": 3.4395,
      "step": 2810
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.378812789916992,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.3609,
      "step": 2820
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.7607951164245605,
      "learning_rate": 2.6416666666666667e-05,
      "loss": 3.3846,
      "step": 2830
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.242066383361816,
      "learning_rate": 2.633333333333333e-05,
      "loss": 3.4369,
      "step": 2840
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.25340461730957,
      "learning_rate": 2.625e-05,
      "loss": 3.4061,
      "step": 2850
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.049473762512207,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 3.3256,
      "step": 2860
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.072059631347656,
      "learning_rate": 2.608333333333333e-05,
      "loss": 3.3666,
      "step": 2870
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.415054321289062,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.5023,
      "step": 2880
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.6795783042907715,
      "learning_rate": 2.5916666666666665e-05,
      "loss": 3.2891,
      "step": 2890
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.70446491241455,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 3.3238,
      "step": 2900
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.6441969871521,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 3.2922,
      "step": 2910
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.163517951965332,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 3.235,
      "step": 2920
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.954649925231934,
      "learning_rate": 2.5583333333333336e-05,
      "loss": 3.3539,
      "step": 2930
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.445436477661133,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.2463,
      "step": 2940
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.121524810791016,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 3.3512,
      "step": 2950
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.81142520904541,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 3.2047,
      "step": 2960
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.366630554199219,
      "learning_rate": 2.525e-05,
      "loss": 3.4453,
      "step": 2970
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.445079803466797,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 3.4148,
      "step": 2980
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.033036231994629,
      "learning_rate": 2.5083333333333338e-05,
      "loss": 3.4529,
      "step": 2990
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.328129768371582,
      "learning_rate": 2.5e-05,
      "loss": 3.3613,
      "step": 3000
    },
    {
      "epoch": 0.1,
      "eval_bleu-4": 0.03719343755617752,
      "eval_rouge-1": 32.097730000000006,
      "eval_rouge-2": 7.163049999999999,
      "eval_rouge-l": 24.698418,
      "eval_runtime": 48.2522,
      "eval_samples_per_second": 1.036,
      "eval_steps_per_second": 0.083,
      "step": 3000
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.902629375457764,
      "learning_rate": 2.4916666666666668e-05,
      "loss": 3.4725,
      "step": 3010
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.941926956176758,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 3.3439,
      "step": 3020
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.993402481079102,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 3.343,
      "step": 3030
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.31549596786499,
      "learning_rate": 2.466666666666667e-05,
      "loss": 3.2225,
      "step": 3040
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.077670097351074,
      "learning_rate": 2.4583333333333332e-05,
      "loss": 3.3871,
      "step": 3050
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.283392429351807,
      "learning_rate": 2.45e-05,
      "loss": 3.5275,
      "step": 3060
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.906732082366943,
      "learning_rate": 2.441666666666667e-05,
      "loss": 3.2932,
      "step": 3070
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.626367568969727,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 3.2922,
      "step": 3080
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.541106224060059,
      "learning_rate": 2.425e-05,
      "loss": 3.2012,
      "step": 3090
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.658968925476074,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 3.3877,
      "step": 3100
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.678098678588867,
      "learning_rate": 2.4083333333333337e-05,
      "loss": 3.3387,
      "step": 3110
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.147541046142578,
      "learning_rate": 2.4e-05,
      "loss": 3.3238,
      "step": 3120
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.89008903503418,
      "learning_rate": 2.3916666666666668e-05,
      "loss": 3.3723,
      "step": 3130
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.278122901916504,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 3.2959,
      "step": 3140
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.884477615356445,
      "learning_rate": 2.375e-05,
      "loss": 3.4504,
      "step": 3150
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.436185836791992,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 3.4234,
      "step": 3160
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.507857799530029,
      "learning_rate": 2.3583333333333335e-05,
      "loss": 3.4777,
      "step": 3170
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.959517002105713,
      "learning_rate": 2.35e-05,
      "loss": 3.215,
      "step": 3180
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.134241580963135,
      "learning_rate": 2.341666666666667e-05,
      "loss": 3.359,
      "step": 3190
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.280900001525879,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.4113,
      "step": 3200
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.686749458312988,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 3.3738,
      "step": 3210
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.348593711853027,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 3.393,
      "step": 3220
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.51713752746582,
      "learning_rate": 2.3083333333333333e-05,
      "loss": 3.4811,
      "step": 3230
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.643387794494629,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.2113,
      "step": 3240
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.231525421142578,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 3.4033,
      "step": 3250
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.924111366271973,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 3.3592,
      "step": 3260
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.138798713684082,
      "learning_rate": 2.275e-05,
      "loss": 3.4094,
      "step": 3270
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.753125190734863,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 3.2914,
      "step": 3280
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.773772239685059,
      "learning_rate": 2.2583333333333335e-05,
      "loss": 3.3033,
      "step": 3290
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.237081050872803,
      "learning_rate": 2.25e-05,
      "loss": 3.3973,
      "step": 3300
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.721992015838623,
      "learning_rate": 2.2416666666666665e-05,
      "loss": 3.3574,
      "step": 3310
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.981471061706543,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 3.224,
      "step": 3320
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.524591445922852,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 3.3926,
      "step": 3330
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.706198692321777,
      "learning_rate": 2.216666666666667e-05,
      "loss": 3.3711,
      "step": 3340
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.92778205871582,
      "learning_rate": 2.2083333333333333e-05,
      "loss": 3.2773,
      "step": 3350
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.861400604248047,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.418,
      "step": 3360
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.524833679199219,
      "learning_rate": 2.191666666666667e-05,
      "loss": 3.323,
      "step": 3370
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.411468029022217,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 3.3711,
      "step": 3380
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.058829307556152,
      "learning_rate": 2.175e-05,
      "loss": 3.2834,
      "step": 3390
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.5537309646606445,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 3.3598,
      "step": 3400
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.566703796386719,
      "learning_rate": 2.1583333333333334e-05,
      "loss": 3.1992,
      "step": 3410
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.807951927185059,
      "learning_rate": 2.15e-05,
      "loss": 3.2809,
      "step": 3420
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.522927284240723,
      "learning_rate": 2.1416666666666668e-05,
      "loss": 3.3357,
      "step": 3430
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.252631187438965,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 3.2975,
      "step": 3440
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.588863372802734,
      "learning_rate": 2.125e-05,
      "loss": 3.3178,
      "step": 3450
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.795479774475098,
      "learning_rate": 2.116666666666667e-05,
      "loss": 3.3352,
      "step": 3460
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.699393272399902,
      "learning_rate": 2.1083333333333335e-05,
      "loss": 3.2637,
      "step": 3470
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.382951736450195,
      "learning_rate": 2.1e-05,
      "loss": 3.2721,
      "step": 3480
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.12787914276123,
      "learning_rate": 2.091666666666667e-05,
      "loss": 3.4078,
      "step": 3490
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.75028657913208,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 3.4355,
      "step": 3500
    },
    {
      "epoch": 0.12,
      "eval_bleu-4": 0.03501962591700101,
      "eval_rouge-1": 31.608768,
      "eval_rouge-2": 6.584942000000002,
      "eval_rouge-l": 24.572739999999996,
      "eval_runtime": 30.7956,
      "eval_samples_per_second": 1.624,
      "eval_steps_per_second": 0.13,
      "step": 3500
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.542447090148926,
      "learning_rate": 2.075e-05,
      "loss": 3.3797,
      "step": 3510
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.71953296661377,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 3.3146,
      "step": 3520
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.142553329467773,
      "learning_rate": 2.0583333333333333e-05,
      "loss": 3.2771,
      "step": 3530
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.464903831481934,
      "learning_rate": 2.05e-05,
      "loss": 3.2975,
      "step": 3540
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.578683853149414,
      "learning_rate": 2.0416666666666667e-05,
      "loss": 3.352,
      "step": 3550
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.064461708068848,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 3.21,
      "step": 3560
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.426459789276123,
      "learning_rate": 2.025e-05,
      "loss": 3.3119,
      "step": 3570
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.103581428527832,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 3.4242,
      "step": 3580
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.076499938964844,
      "learning_rate": 2.0083333333333335e-05,
      "loss": 3.2357,
      "step": 3590
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.383018493652344,
      "learning_rate": 2e-05,
      "loss": 3.1855,
      "step": 3600
    },
    {
      "epoch": 0.13,
      "grad_norm": 10.259682655334473,
      "learning_rate": 1.9916666666666665e-05,
      "loss": 3.2643,
      "step": 3610
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.269691467285156,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 3.5312,
      "step": 3620
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.122008323669434,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 3.393,
      "step": 3630
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.424446105957031,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 3.1967,
      "step": 3640
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.076838493347168,
      "learning_rate": 1.9583333333333333e-05,
      "loss": 3.3014,
      "step": 3650
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.977139472961426,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.1959,
      "step": 3660
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.15282917022705,
      "learning_rate": 1.9416666666666667e-05,
      "loss": 3.2959,
      "step": 3670
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.311176300048828,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 3.3715,
      "step": 3680
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.72415018081665,
      "learning_rate": 1.925e-05,
      "loss": 3.3969,
      "step": 3690
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.12186050415039,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 3.3979,
      "step": 3700
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.276156425476074,
      "learning_rate": 1.9083333333333334e-05,
      "loss": 3.3633,
      "step": 3710
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.387052536010742,
      "learning_rate": 1.9e-05,
      "loss": 3.3771,
      "step": 3720
    },
    {
      "epoch": 0.13,
      "grad_norm": 10.30410099029541,
      "learning_rate": 1.8916666666666668e-05,
      "loss": 3.1656,
      "step": 3730
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.620616912841797,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 3.3936,
      "step": 3740
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.9344305992126465,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.2215,
      "step": 3750
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.200064659118652,
      "learning_rate": 1.866666666666667e-05,
      "loss": 3.2,
      "step": 3760
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.873966217041016,
      "learning_rate": 1.8583333333333332e-05,
      "loss": 3.2393,
      "step": 3770
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.082222938537598,
      "learning_rate": 1.85e-05,
      "loss": 3.2723,
      "step": 3780
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.769711017608643,
      "learning_rate": 1.841666666666667e-05,
      "loss": 3.4631,
      "step": 3790
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.172127723693848,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 3.2508,
      "step": 3800
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.79946517944336,
      "learning_rate": 1.825e-05,
      "loss": 3.3393,
      "step": 3810
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.597536087036133,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 3.2219,
      "step": 3820
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.564845085144043,
      "learning_rate": 1.8083333333333337e-05,
      "loss": 3.382,
      "step": 3830
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.704061508178711,
      "learning_rate": 1.8e-05,
      "loss": 3.3092,
      "step": 3840
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.724284172058105,
      "learning_rate": 1.7916666666666667e-05,
      "loss": 3.2816,
      "step": 3850
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.918208122253418,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 3.3234,
      "step": 3860
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.819770336151123,
      "learning_rate": 1.775e-05,
      "loss": 3.4576,
      "step": 3870
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.877864837646484,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 3.4789,
      "step": 3880
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.840423583984375,
      "learning_rate": 1.7583333333333335e-05,
      "loss": 3.4092,
      "step": 3890
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.238038063049316,
      "learning_rate": 1.75e-05,
      "loss": 3.4379,
      "step": 3900
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.481681823730469,
      "learning_rate": 1.741666666666667e-05,
      "loss": 3.2721,
      "step": 3910
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.99177360534668,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 3.3381,
      "step": 3920
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.594860553741455,
      "learning_rate": 1.725e-05,
      "loss": 3.3805,
      "step": 3930
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.26938247680664,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 3.5008,
      "step": 3940
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.889331817626953,
      "learning_rate": 1.7083333333333333e-05,
      "loss": 3.3283,
      "step": 3950
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.372685432434082,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.2811,
      "step": 3960
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.504762172698975,
      "learning_rate": 1.6916666666666667e-05,
      "loss": 3.4119,
      "step": 3970
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.59191608428955,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 3.4055,
      "step": 3980
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.483810424804688,
      "learning_rate": 1.675e-05,
      "loss": 3.4279,
      "step": 3990
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.361093521118164,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 3.3797,
      "step": 4000
    },
    {
      "epoch": 0.14,
      "eval_bleu-4": 0.03904650180030107,
      "eval_rouge-1": 32.75648,
      "eval_rouge-2": 7.9515080000000005,
      "eval_rouge-l": 25.535922,
      "eval_runtime": 30.7457,
      "eval_samples_per_second": 1.626,
      "eval_steps_per_second": 0.13,
      "step": 4000
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.266379356384277,
      "learning_rate": 1.6583333333333334e-05,
      "loss": 3.2568,
      "step": 4010
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.103050231933594,
      "learning_rate": 1.65e-05,
      "loss": 3.3457,
      "step": 4020
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.389849662780762,
      "learning_rate": 1.6416666666666665e-05,
      "loss": 3.4385,
      "step": 4030
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.13595199584961,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 3.3678,
      "step": 4040
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.365612983703613,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 3.2566,
      "step": 4050
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.909453392028809,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 3.2973,
      "step": 4060
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.7159223556518555,
      "learning_rate": 1.6083333333333332e-05,
      "loss": 3.1662,
      "step": 4070
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.62748908996582,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.3902,
      "step": 4080
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.407302856445312,
      "learning_rate": 1.591666666666667e-05,
      "loss": 3.4242,
      "step": 4090
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.699140548706055,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 3.3223,
      "step": 4100
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.668933868408203,
      "learning_rate": 1.575e-05,
      "loss": 3.3551,
      "step": 4110
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.278091430664062,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 3.3164,
      "step": 4120
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.585442543029785,
      "learning_rate": 1.5583333333333334e-05,
      "loss": 3.4158,
      "step": 4130
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.004690170288086,
      "learning_rate": 1.55e-05,
      "loss": 3.277,
      "step": 4140
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.726473808288574,
      "learning_rate": 1.5416666666666668e-05,
      "loss": 3.332,
      "step": 4150
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.706713676452637,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 3.3219,
      "step": 4160
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.421919822692871,
      "learning_rate": 1.525e-05,
      "loss": 3.2408,
      "step": 4170
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.175848007202148,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 3.3246,
      "step": 4180
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.81942367553711,
      "learning_rate": 1.5083333333333335e-05,
      "loss": 3.4805,
      "step": 4190
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.013941764831543,
      "learning_rate": 1.5e-05,
      "loss": 3.3719,
      "step": 4200
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.602559566497803,
      "learning_rate": 1.4916666666666667e-05,
      "loss": 3.3289,
      "step": 4210
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.277746200561523,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 3.3223,
      "step": 4220
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.348013877868652,
      "learning_rate": 1.475e-05,
      "loss": 3.2877,
      "step": 4230
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.95429801940918,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 3.4711,
      "step": 4240
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.176736831665039,
      "learning_rate": 1.4583333333333335e-05,
      "loss": 3.3922,
      "step": 4250
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.588557243347168,
      "learning_rate": 1.45e-05,
      "loss": 3.3473,
      "step": 4260
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.404525756835938,
      "learning_rate": 1.4416666666666667e-05,
      "loss": 3.2373,
      "step": 4270
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.190330505371094,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 3.1727,
      "step": 4280
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.147708892822266,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 3.2918,
      "step": 4290
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.512513160705566,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 3.3885,
      "step": 4300
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.516962051391602,
      "learning_rate": 1.4083333333333335e-05,
      "loss": 3.3893,
      "step": 4310
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.350258827209473,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.182,
      "step": 4320
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.758065223693848,
      "learning_rate": 1.3916666666666667e-05,
      "loss": 3.2115,
      "step": 4330
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.173404693603516,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 3.3479,
      "step": 4340
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.362357139587402,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 3.2805,
      "step": 4350
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.137274742126465,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 3.2789,
      "step": 4360
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.21342945098877,
      "learning_rate": 1.3583333333333334e-05,
      "loss": 3.3557,
      "step": 4370
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.456385612487793,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.3748,
      "step": 4380
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.674168586730957,
      "learning_rate": 1.3416666666666666e-05,
      "loss": 3.1922,
      "step": 4390
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.319657325744629,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 3.3086,
      "step": 4400
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.870387077331543,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 3.2711,
      "step": 4410
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.192451477050781,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 3.3332,
      "step": 4420
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.931361198425293,
      "learning_rate": 1.3083333333333334e-05,
      "loss": 3.415,
      "step": 4430
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.715255737304688,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.1168,
      "step": 4440
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.632617950439453,
      "learning_rate": 1.2916666666666668e-05,
      "loss": 3.2537,
      "step": 4450
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.051874160766602,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 3.3428,
      "step": 4460
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.664904594421387,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 3.425,
      "step": 4470
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.929403305053711,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 3.3648,
      "step": 4480
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.422054290771484,
      "learning_rate": 1.2583333333333334e-05,
      "loss": 3.3141,
      "step": 4490
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.224451065063477,
      "learning_rate": 1.25e-05,
      "loss": 3.366,
      "step": 4500
    },
    {
      "epoch": 0.16,
      "eval_bleu-4": 0.03210187305582873,
      "eval_rouge-1": 31.34973,
      "eval_rouge-2": 6.797316,
      "eval_rouge-l": 23.691698000000002,
      "eval_runtime": 47.4008,
      "eval_samples_per_second": 1.055,
      "eval_steps_per_second": 0.084,
      "step": 4500
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.188309669494629,
      "learning_rate": 1.2416666666666667e-05,
      "loss": 3.4455,
      "step": 4510
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.485464096069336,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 3.1914,
      "step": 4520
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.170743942260742,
      "learning_rate": 1.225e-05,
      "loss": 3.3639,
      "step": 4530
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.781054496765137,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 3.3436,
      "step": 4540
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.936506271362305,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 3.1723,
      "step": 4550
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.23916244506836,
      "learning_rate": 1.2e-05,
      "loss": 3.3309,
      "step": 4560
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.535673141479492,
      "learning_rate": 1.1916666666666667e-05,
      "loss": 3.3957,
      "step": 4570
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.711278915405273,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 3.2426,
      "step": 4580
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.466216087341309,
      "learning_rate": 1.175e-05,
      "loss": 3.3367,
      "step": 4590
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.17635726928711,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 3.2771,
      "step": 4600
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.92883586883545,
      "learning_rate": 1.1583333333333333e-05,
      "loss": 3.2418,
      "step": 4610
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.690705299377441,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 3.3971,
      "step": 4620
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.0737943649292,
      "learning_rate": 1.1416666666666667e-05,
      "loss": 3.3166,
      "step": 4630
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.200061798095703,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 3.3621,
      "step": 4640
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.524633407592773,
      "learning_rate": 1.125e-05,
      "loss": 3.3045,
      "step": 4650
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.349780082702637,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 3.3852,
      "step": 4660
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.31457805633545,
      "learning_rate": 1.1083333333333335e-05,
      "loss": 3.3816,
      "step": 4670
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.508894920349121,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 3.5305,
      "step": 4680
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.836553573608398,
      "learning_rate": 1.0916666666666667e-05,
      "loss": 3.3447,
      "step": 4690
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.877827644348145,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 3.49,
      "step": 4700
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.72954273223877,
      "learning_rate": 1.075e-05,
      "loss": 3.4291,
      "step": 4710
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.093795776367188,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 3.2924,
      "step": 4720
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.749667167663574,
      "learning_rate": 1.0583333333333334e-05,
      "loss": 3.4211,
      "step": 4730
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.584635734558105,
      "learning_rate": 1.05e-05,
      "loss": 3.2455,
      "step": 4740
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.724239349365234,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 3.4057,
      "step": 4750
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.279241561889648,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 3.3162,
      "step": 4760
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.101516723632812,
      "learning_rate": 1.025e-05,
      "loss": 3.3189,
      "step": 4770
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.05228328704834,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 3.3307,
      "step": 4780
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.693875312805176,
      "learning_rate": 1.0083333333333334e-05,
      "loss": 3.4131,
      "step": 4790
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.561858177185059,
      "learning_rate": 1e-05,
      "loss": 3.3934,
      "step": 4800
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.289963722229004,
      "learning_rate": 9.916666666666668e-06,
      "loss": 3.5656,
      "step": 4810
    },
    {
      "epoch": 0.17,
      "grad_norm": 10.311807632446289,
      "learning_rate": 9.833333333333333e-06,
      "loss": 3.2611,
      "step": 4820
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.014984130859375,
      "learning_rate": 9.750000000000002e-06,
      "loss": 3.1828,
      "step": 4830
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.577553749084473,
      "learning_rate": 9.666666666666667e-06,
      "loss": 3.2398,
      "step": 4840
    },
    {
      "epoch": 0.17,
      "grad_norm": 10.463404655456543,
      "learning_rate": 9.583333333333334e-06,
      "loss": 3.3312,
      "step": 4850
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.630748748779297,
      "learning_rate": 9.5e-06,
      "loss": 3.1873,
      "step": 4860
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.269449234008789,
      "learning_rate": 9.416666666666667e-06,
      "loss": 3.2588,
      "step": 4870
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.048022270202637,
      "learning_rate": 9.333333333333334e-06,
      "loss": 3.393,
      "step": 4880
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.901495933532715,
      "learning_rate": 9.25e-06,
      "loss": 3.3994,
      "step": 4890
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.35677719116211,
      "learning_rate": 9.166666666666666e-06,
      "loss": 3.2959,
      "step": 4900
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.234469413757324,
      "learning_rate": 9.083333333333333e-06,
      "loss": 3.2338,
      "step": 4910
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.940033912658691,
      "learning_rate": 9e-06,
      "loss": 3.3781,
      "step": 4920
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.752266883850098,
      "learning_rate": 8.916666666666667e-06,
      "loss": 3.1902,
      "step": 4930
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.879167556762695,
      "learning_rate": 8.833333333333334e-06,
      "loss": 3.3256,
      "step": 4940
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.576824188232422,
      "learning_rate": 8.75e-06,
      "loss": 3.3008,
      "step": 4950
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.724501609802246,
      "learning_rate": 8.666666666666668e-06,
      "loss": 3.4285,
      "step": 4960
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.753133773803711,
      "learning_rate": 8.583333333333333e-06,
      "loss": 3.299,
      "step": 4970
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.25092601776123,
      "learning_rate": 8.500000000000002e-06,
      "loss": 3.293,
      "step": 4980
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.608033180236816,
      "learning_rate": 8.416666666666667e-06,
      "loss": 3.2189,
      "step": 4990
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.250938415527344,
      "learning_rate": 8.333333333333334e-06,
      "loss": 3.1629,
      "step": 5000
    },
    {
      "epoch": 0.17,
      "eval_bleu-4": 0.02994436423773491,
      "eval_rouge-1": 32.166564,
      "eval_rouge-2": 6.940996,
      "eval_rouge-l": 23.891219999999997,
      "eval_runtime": 65.2078,
      "eval_samples_per_second": 0.767,
      "eval_steps_per_second": 0.061,
      "step": 5000
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.508313179016113,
      "learning_rate": 8.25e-06,
      "loss": 3.3977,
      "step": 5010
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.55482006072998,
      "learning_rate": 8.166666666666668e-06,
      "loss": 3.2979,
      "step": 5020
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.954744815826416,
      "learning_rate": 8.083333333333333e-06,
      "loss": 3.2988,
      "step": 5030
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.224771499633789,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.2523,
      "step": 5040
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.292013168334961,
      "learning_rate": 7.916666666666667e-06,
      "loss": 3.274,
      "step": 5050
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.050227165222168,
      "learning_rate": 7.833333333333333e-06,
      "loss": 3.3998,
      "step": 5060
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.850117206573486,
      "learning_rate": 7.75e-06,
      "loss": 3.3928,
      "step": 5070
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.56580638885498,
      "learning_rate": 7.666666666666667e-06,
      "loss": 3.3664,
      "step": 5080
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.011576652526855,
      "learning_rate": 7.583333333333334e-06,
      "loss": 3.402,
      "step": 5090
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.19252872467041,
      "learning_rate": 7.5e-06,
      "loss": 3.3047,
      "step": 5100
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.372109413146973,
      "learning_rate": 7.416666666666668e-06,
      "loss": 3.3072,
      "step": 5110
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.120771408081055,
      "learning_rate": 7.333333333333334e-06,
      "loss": 3.3418,
      "step": 5120
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.212539672851562,
      "learning_rate": 7.25e-06,
      "loss": 3.3357,
      "step": 5130
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.23204517364502,
      "learning_rate": 7.166666666666667e-06,
      "loss": 3.1676,
      "step": 5140
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.358583450317383,
      "learning_rate": 7.083333333333334e-06,
      "loss": 3.3311,
      "step": 5150
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.99257755279541,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.2754,
      "step": 5160
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.64570426940918,
      "learning_rate": 6.916666666666667e-06,
      "loss": 3.3463,
      "step": 5170
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.424803733825684,
      "learning_rate": 6.833333333333333e-06,
      "loss": 3.2342,
      "step": 5180
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.127063751220703,
      "learning_rate": 6.750000000000001e-06,
      "loss": 3.3576,
      "step": 5190
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.39771842956543,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.3762,
      "step": 5200
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.383767127990723,
      "learning_rate": 6.583333333333333e-06,
      "loss": 3.3863,
      "step": 5210
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.71362018585205,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 3.3393,
      "step": 5220
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.417984962463379,
      "learning_rate": 6.4166666666666665e-06,
      "loss": 3.3217,
      "step": 5230
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.077637672424316,
      "learning_rate": 6.333333333333334e-06,
      "loss": 3.4566,
      "step": 5240
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.205052375793457,
      "learning_rate": 6.25e-06,
      "loss": 3.2418,
      "step": 5250
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.891465187072754,
      "learning_rate": 6.166666666666667e-06,
      "loss": 3.2184,
      "step": 5260
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.502599716186523,
      "learning_rate": 6.083333333333334e-06,
      "loss": 3.1863,
      "step": 5270
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.380668640136719,
      "learning_rate": 6e-06,
      "loss": 3.0846,
      "step": 5280
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.877845764160156,
      "learning_rate": 5.916666666666667e-06,
      "loss": 3.2986,
      "step": 5290
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.85852336883545,
      "learning_rate": 5.833333333333334e-06,
      "loss": 3.1178,
      "step": 5300
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.653837203979492,
      "learning_rate": 5.750000000000001e-06,
      "loss": 3.2873,
      "step": 5310
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.29704761505127,
      "learning_rate": 5.666666666666667e-06,
      "loss": 3.2939,
      "step": 5320
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.105072975158691,
      "learning_rate": 5.583333333333334e-06,
      "loss": 3.2025,
      "step": 5330
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.83651065826416,
      "learning_rate": 5.500000000000001e-06,
      "loss": 3.359,
      "step": 5340
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.856688499450684,
      "learning_rate": 5.416666666666667e-06,
      "loss": 3.2436,
      "step": 5350
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.261240005493164,
      "learning_rate": 5.333333333333334e-06,
      "loss": 3.2504,
      "step": 5360
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.56330680847168,
      "learning_rate": 5.25e-06,
      "loss": 3.19,
      "step": 5370
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.382623672485352,
      "learning_rate": 5.166666666666667e-06,
      "loss": 3.451,
      "step": 5380
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.979506492614746,
      "learning_rate": 5.0833333333333335e-06,
      "loss": 3.1414,
      "step": 5390
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.714202880859375,
      "learning_rate": 5e-06,
      "loss": 3.3367,
      "step": 5400
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.814483642578125,
      "learning_rate": 4.9166666666666665e-06,
      "loss": 3.4148,
      "step": 5410
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.980402946472168,
      "learning_rate": 4.833333333333333e-06,
      "loss": 3.3064,
      "step": 5420
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.736725807189941,
      "learning_rate": 4.75e-06,
      "loss": 3.3178,
      "step": 5430
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.751091957092285,
      "learning_rate": 4.666666666666667e-06,
      "loss": 3.2309,
      "step": 5440
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.02685832977295,
      "learning_rate": 4.583333333333333e-06,
      "loss": 3.3314,
      "step": 5450
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.32792854309082,
      "learning_rate": 4.5e-06,
      "loss": 3.4014,
      "step": 5460
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.438887596130371,
      "learning_rate": 4.416666666666667e-06,
      "loss": 3.1621,
      "step": 5470
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.9805908203125,
      "learning_rate": 4.333333333333334e-06,
      "loss": 3.2857,
      "step": 5480
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.690855979919434,
      "learning_rate": 4.250000000000001e-06,
      "loss": 3.3301,
      "step": 5490
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.02505111694336,
      "learning_rate": 4.166666666666667e-06,
      "loss": 3.2656,
      "step": 5500
    },
    {
      "epoch": 0.19,
      "eval_bleu-4": 0.03242241669333962,
      "eval_rouge-1": 31.535358000000002,
      "eval_rouge-2": 6.593712,
      "eval_rouge-l": 24.525130000000004,
      "eval_runtime": 47.917,
      "eval_samples_per_second": 1.043,
      "eval_steps_per_second": 0.083,
      "step": 5500
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.858624458312988,
      "learning_rate": 4.083333333333334e-06,
      "loss": 3.3141,
      "step": 5510
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.02485466003418,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.3826,
      "step": 5520
    },
    {
      "epoch": 0.19,
      "grad_norm": 11.480061531066895,
      "learning_rate": 3.916666666666667e-06,
      "loss": 3.4486,
      "step": 5530
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.893115043640137,
      "learning_rate": 3.833333333333334e-06,
      "loss": 3.3783,
      "step": 5540
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.85126781463623,
      "learning_rate": 3.75e-06,
      "loss": 3.2531,
      "step": 5550
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.797554969787598,
      "learning_rate": 3.666666666666667e-06,
      "loss": 3.2756,
      "step": 5560
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.132856369018555,
      "learning_rate": 3.5833333333333335e-06,
      "loss": 3.2441,
      "step": 5570
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.865823745727539,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 3.3088,
      "step": 5580
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.395384788513184,
      "learning_rate": 3.4166666666666664e-06,
      "loss": 3.3229,
      "step": 5590
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.920454025268555,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.2885,
      "step": 5600
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.549237251281738,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 3.343,
      "step": 5610
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.078743934631348,
      "learning_rate": 3.166666666666667e-06,
      "loss": 3.2557,
      "step": 5620
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.863204002380371,
      "learning_rate": 3.0833333333333336e-06,
      "loss": 3.3711,
      "step": 5630
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.702400207519531,
      "learning_rate": 3e-06,
      "loss": 3.315,
      "step": 5640
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.2242431640625,
      "learning_rate": 2.916666666666667e-06,
      "loss": 3.3377,
      "step": 5650
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.728897094726562,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 3.4424,
      "step": 5660
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.691568374633789,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 3.3021,
      "step": 5670
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.051350593566895,
      "learning_rate": 2.666666666666667e-06,
      "loss": 3.3926,
      "step": 5680
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.41071891784668,
      "learning_rate": 2.5833333333333333e-06,
      "loss": 3.2891,
      "step": 5690
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.759822845458984,
      "learning_rate": 2.5e-06,
      "loss": 3.3158,
      "step": 5700
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.346451759338379,
      "learning_rate": 2.4166666666666667e-06,
      "loss": 3.4197,
      "step": 5710
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.933706283569336,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 3.2641,
      "step": 5720
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.260066986083984,
      "learning_rate": 2.25e-06,
      "loss": 3.2982,
      "step": 5730
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.989583015441895,
      "learning_rate": 2.166666666666667e-06,
      "loss": 3.4143,
      "step": 5740
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.40821361541748,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 3.3824,
      "step": 5750
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.144302368164062,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.3602,
      "step": 5760
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.208096504211426,
      "learning_rate": 1.916666666666667e-06,
      "loss": 3.2348,
      "step": 5770
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.237564086914062,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 3.3283,
      "step": 5780
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.12198543548584,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 3.4039,
      "step": 5790
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.888230323791504,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 3.3836,
      "step": 5800
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.638331413269043,
      "learning_rate": 1.5833333333333336e-06,
      "loss": 3.2885,
      "step": 5810
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.578680038452148,
      "learning_rate": 1.5e-06,
      "loss": 3.2064,
      "step": 5820
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.23885726928711,
      "learning_rate": 1.4166666666666667e-06,
      "loss": 3.2391,
      "step": 5830
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.742545127868652,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 3.2641,
      "step": 5840
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.83415699005127,
      "learning_rate": 1.25e-06,
      "loss": 3.2967,
      "step": 5850
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.996827602386475,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 3.1465,
      "step": 5860
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.487971305847168,
      "learning_rate": 1.0833333333333335e-06,
      "loss": 3.1443,
      "step": 5870
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.785512447357178,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 3.3367,
      "step": 5880
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.968988418579102,
      "learning_rate": 9.166666666666667e-07,
      "loss": 3.2006,
      "step": 5890
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.096807479858398,
      "learning_rate": 8.333333333333333e-07,
      "loss": 3.274,
      "step": 5900
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.122106552124023,
      "learning_rate": 7.5e-07,
      "loss": 3.3992,
      "step": 5910
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.21808910369873,
      "learning_rate": 6.666666666666667e-07,
      "loss": 3.5336,
      "step": 5920
    },
    {
      "epoch": 0.21,
      "grad_norm": 10.203095436096191,
      "learning_rate": 5.833333333333334e-07,
      "loss": 3.3027,
      "step": 5930
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.313584327697754,
      "learning_rate": 5.000000000000001e-07,
      "loss": 3.4311,
      "step": 5940
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.793971061706543,
      "learning_rate": 4.1666666666666667e-07,
      "loss": 3.3953,
      "step": 5950
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.590604782104492,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 3.4426,
      "step": 5960
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.632950782775879,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 3.3408,
      "step": 5970
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.876246452331543,
      "learning_rate": 1.6666666666666668e-07,
      "loss": 3.3689,
      "step": 5980
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.80276870727539,
      "learning_rate": 8.333333333333334e-08,
      "loss": 3.3311,
      "step": 5990
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.272966384887695,
      "learning_rate": 0.0,
      "loss": 3.4051,
      "step": 6000
    },
    {
      "epoch": 0.21,
      "eval_bleu-4": 0.03010695267870934,
      "eval_rouge-1": 31.535719999999998,
      "eval_rouge-2": 6.778764,
      "eval_rouge-l": 23.321336000000002,
      "eval_runtime": 80.8365,
      "eval_samples_per_second": 0.619,
      "eval_steps_per_second": 0.049,
      "step": 6000
    }
  ],
  "logging_steps": 10,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.3022816714396467e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
